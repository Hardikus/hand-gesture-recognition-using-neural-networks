{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this project, we are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Import libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization\n",
    "from keras.layers import Activation, Dropout, ZeroPadding3D\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling3D, Conv3D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "rn.seed(30)\n",
    "tf.set_random_seed(30)\n",
    "\n",
    "train_path = './Project_data/train'\n",
    "val_path = './Project_data/val'\n",
    "train_doc = np.random.permutation(open('./Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('./Project_data/val.csv').readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Class\n",
    "This is one of the most important part of the code. The overall structure of the generator is broken down into modules. In the generator, we are going to preprocess the images as we have images of 2 different dimensions as well as create a batch of video frames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, width=120, height=120, frames=30, channel=3, \n",
    "                 crop = True, normalize = False, affine = False, flip = False, edge = False  ):\n",
    "        self.width = width   # X dimension of the image\n",
    "        self.height = height # Y dimesnion of the image\n",
    "        self.frames = frames # length/depth of the video frames\n",
    "        self.channel = channel # number of channels in images 3 for color(RGB) and 1 for Gray  \n",
    "        self.affine = affine # augment data with affine transform of the image\n",
    "        self.flip = flip\n",
    "        self.normalize =  normalize\n",
    "        self.edge = edge # edge detection\n",
    "        self.crop = crop\n",
    "\n",
    "    # Helper function to generate a random affine transform on the image\n",
    "    def __get_random_affine(self): # private method\n",
    "        dx, dy = np.random.randint(-1.7, 1.8, 2)\n",
    "        M = np.float32([[1, 0, dx], [0, 1, dy]])\n",
    "        return M\n",
    "\n",
    "    # Helper function to initialize all the batch image data and labels\n",
    "    def __init_batch_data(self, batch_size): # private method\n",
    "        batch_data = np.zeros((batch_size, self.frames, self.width, self.height, self.channel)) \n",
    "        batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "    def __load_batch_images(self, source_path, folder_list, batch_num, batch_size, t): # private method\n",
    "    \n",
    "        batch_data,batch_labels = self.__init_batch_data(batch_size)\n",
    "        # We will also build a agumented batch data\n",
    "        if self.affine:\n",
    "            batch_data_aug,batch_labels_aug = self.__init_batch_data(batch_size)\n",
    "        if self.flip:\n",
    "            batch_data_flip,batch_labels_flip = self.__init_batch_data(batch_size)\n",
    "\n",
    "        #create a list of image numbers you want to use for a particular video\n",
    "        img_idx = [x for x in range(0, self.frames)] \n",
    "\n",
    "        for folder in range(batch_size): # iterate over the batch_size\n",
    "            # read all the images in the folder\n",
    "            imgs = sorted(os.listdir(source_path+'/'+ t[folder + (batch_num*batch_size)].split(';')[0])) \n",
    "            # Generate a random affine to be used in image transformation for buidling agumented data set\n",
    "            M = self.__get_random_affine()\n",
    "            \n",
    "            #  Iterate over the frames/images of a folder to read them in\n",
    "            for idx, item in enumerate(img_idx): \n",
    "                image = cv2.imread(source_path+'/'+ t[folder + (batch_num*batch_size)].strip().split(';')[0]+'/'+imgs[item], cv2.IMREAD_COLOR)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                #and the conv3D will throw error if the inputs in a batch have different shapes  \n",
    "                if self.crop:\n",
    "                    image = self.__crop(image)\n",
    "                # If normalize is set normalize the image else use the raw image.\n",
    "                if self.normalize:\n",
    "                    resized = self.__normalize(self.__resize(image))\n",
    "                else:\n",
    "                    resized = self.__resize(image)\n",
    "                # If the input is edge detected image then use the sobelx, sobely and laplacian as 3 channel of the edge detected image\n",
    "                if self.edge:\n",
    "                    resized = self.__edge(resized)\n",
    "                \n",
    "                batch_data[folder,idx] = resized\n",
    "                if self.affine:\n",
    "                    batch_data_aug[folder,idx] = self.__affine(resized, M)   \n",
    "                if self.flip:\n",
    "                    batch_data_flip[folder,idx] = self.__flip(resized)   \n",
    "\n",
    "            batch_labels[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "            if self.affine:\n",
    "                batch_labels_aug[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "            \n",
    "            if self.flip:\n",
    "                if int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==0:\n",
    "                    batch_labels_flip[folder, 1] = 1\n",
    "                elif int(t[folder + (batch_num*batch_size)].strip().split(';')[2])==1:\n",
    "                    batch_labels_flip[folder, 0] = 1\n",
    "                else:\n",
    "                    batch_labels_flip[folder, int(t[folder + (batch_num*batch_size)].strip().split(';')[2])] = 1\n",
    "        \n",
    "        if self.affine:\n",
    "            batch_data = np.append(batch_data, batch_data_aug, axis = 0) \n",
    "            batch_labels = np.append(batch_labels, batch_labels_aug, axis = 0) \n",
    "        if self.flip:\n",
    "            batch_data = np.append(batch_data, batch_data_flip, axis = 0) \n",
    "            batch_labels = np.append(batch_labels, batch_labels_flip, axis = 0) \n",
    "\n",
    "        return batch_data, batch_labels\n",
    "    \n",
    "    def generator(self, source_path, folder_list, batch_size): # public method\n",
    "        print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "                yield self.__load_batch_images(source_path, folder_list, batch, batch_size, t) \n",
    "            \n",
    "            # Code for the remaining data points which are left after full batches\n",
    "            if (len(folder_list) != batch_size*num_batches):\n",
    "                batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "                yield self.__load_batch_images(source_path, folder_list, num_batches, batch_size, t)\n",
    "\n",
    "    # Helper function to perfom affice transform on the image\n",
    "    def __affine(self, image, M):\n",
    "        return cv2.warpAffine(image, M, (image.shape[0], image.shape[1]))\n",
    "\n",
    "    # Helper function to flip the image\n",
    "    def __flip(self, image):\n",
    "        return np.flip(image,1)\n",
    "    \n",
    "    # Helper function to normalise the data\n",
    "    def __normalize(self, image):\n",
    "        return image/127.5-1\n",
    "    \n",
    "    # Helper function to resize the image\n",
    "    def __resize(self, image):\n",
    "        return cv2.resize(image, (self.width,self.height), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Helper function to crop the image\n",
    "    def __crop(self, image):\n",
    "        if image.shape[0] != image.shape[1]:\n",
    "            return image[0:120, 20:140]\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    # Helper function for edge detection\n",
    "    def __edge(self, image):\n",
    "        edge = np.zeros((image.shape[0], image.shape[1], image.shape[2]))\n",
    "        edge[:,:,0] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,0],(3,3),0),cv2.CV_64F)\n",
    "        edge[:,:,1] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,1],(3,3),0),cv2.CV_64F)\n",
    "        edge[:,:,2] = cv2.Laplacian(cv2.GaussianBlur(image[:,:,2],(3,3),0),cv2.CV_64F)\n",
    "        return edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelGenerator(object):\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d1(cls, input_shape, nb_classes):\n",
    "        \"\"\"\n",
    "        Build a 3D convolutional network, based loosely on C3D.\n",
    "            https://arxiv.org/pdf/1412.0767.pdf\n",
    "        \"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(\n",
    "            8, (3,3,3), activation='relu', input_shape=input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(16, (3,3,3), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(32, (3,3,3), activation='relu'))\n",
    "        model.add(Conv3D(32, (3,3,3), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "        model.add(Conv3D(64, (2,2,2), activation='relu'))\n",
    "        model.add(Conv3D(64, (2,2,2), activation='relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(256))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d2(cls, input_shape, nb_classes):\n",
    "        \"\"\"\n",
    "        Build a 3D convolutional network, aka C3D.\n",
    "            https://arxiv.org/pdf/1412.0767.pdf\n",
    "        \"\"\"        \n",
    "        model = Sequential()\n",
    "        # 1st layer group\n",
    "        model.add(Conv3D(16, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv1',\n",
    "                         subsample=(1, 1, 1),\n",
    "                         input_shape=input_shape))\n",
    "        model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                               border_mode='valid', name='pool1'))\n",
    "        # 2nd layer group\n",
    "        model.add(Conv3D(32, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv2',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool2'))\n",
    "        # 3rd layer group\n",
    "        model.add(Conv3D(64, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv3a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(64, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv3b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool3'))\n",
    "        # 4th layer group\n",
    "        model.add(Conv3D(128, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv4a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(128, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv4b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               border_mode='valid', name='pool4'))\n",
    "\n",
    "        # 5th layer group\n",
    "        model.add(Conv3D(256, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv5a',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(Conv3D(256, 3, 3, 3, activation='relu',\n",
    "                         padding='same', name='conv5b',\n",
    "                         subsample=(1, 1, 1)))\n",
    "        model.add(ZeroPadding3D(padding=(0, 1, 1)))\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                               padding='valid', name='pool5'))\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # FC layers group\n",
    "        model.add(Dense(512, activation='relu', name='fc6'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512, activation='relu', name='fc7'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d3(cls, input_shape, nb_classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, kernel_size=(3, 3, 3), input_shape=input_shape, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(16, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv3D(32, padding=\"same\", kernel_size=(3, 3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling3D(pool_size=(3, 3, 3), padding=\"same\"))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    " \n",
    "    @classmethod\n",
    "    def c3d4(cls, input_shape, nb_classes):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv3D(8, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(16, kernel_size=(3,3,3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        #Flatten Layers\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #softmax layer\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        return model\n",
    "    \n",
    "    @classmethod\n",
    "    def c3d5(cls, input_shape, nb_classes):\n",
    "        # Define model\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv3D(8, kernel_size=(3,3,3), input_shape=input_shape, padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(16, kernel_size=(3,3,3), padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(32, kernel_size=(1,3,3), padding='same'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        model.add(Conv3D(64, kernel_size=(1,3,3), padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "        #Flatten Layers\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        #softmax layer\n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "        return model   \n",
    "    \n",
    "    @classmethod\n",
    "    def lstm(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a simple LSTM network. We pass the extracted features from\n",
    "        our CNN to this model predomenently.\"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(2048, return_sequences=False,\n",
    "                       input_shape=input_shape,\n",
    "                       dropout=0.5))\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def lrcn(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),\n",
    "            activation='relu', padding='same'), input_shape=input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "            kernel_initializer=\"he_normal\", activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def mlp(cls, input_shape, nb_classes):\n",
    "        \"\"\"Build a simple MLP. It uses extracted features as the input\n",
    "        because of the otherwise too-high dimensionality.\"\"\"\n",
    "        # Model.\n",
    "        model = Sequential()\n",
    "        model.add(Flatten(input_shape=input_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(512))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, num_epochs, model, train_generator, val_generator, optimiser=None):\n",
    "\n",
    "    curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "    num_train_sequences = len(train_doc)\n",
    "    print('# training sequences =', num_train_sequences)\n",
    "    num_val_sequences = len(val_doc)\n",
    "    print('# validation sequences =', num_val_sequences)\n",
    "    print('# batch size =', batch_size)    \n",
    "    print('# epochs =', num_epochs)\n",
    "\n",
    "    #optimizer = Adam(lr=rate) \n",
    "    #write your optimizer\n",
    "    if optimiser == None:\n",
    "        optimiser = Adam() \n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print (model.summary())\n",
    "    \n",
    "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "            \n",
    "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "    checkpoint = ModelCheckpoint(filepath, \n",
    "                                 monitor='val_loss', \n",
    "                                 verbose=1, \n",
    "                                 save_best_only=False, \n",
    "                                 save_weights_only=False, \n",
    "                                 mode='auto', \n",
    "                                 period=1)\n",
    "    LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "    callbacks_list = [checkpoint, LR]\n",
    "\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "\n",
    "    model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                callbacks=callbacks_list, validation_data=val_generator, \n",
    "                validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "def clear_cuda():\n",
    "    #cuda.select_device(0)\n",
    "    #cuda.close()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(16, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv1\", input_shape=(30, 120, ..., strides=(1, 1, 1))`\n",
      "  \n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  app.launch_new_instance()\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(32, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv2\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv3b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv4b\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5a\", strides=(1, 1, 1))`\n",
      "/home/santhosh/anaconda3/envs/tensor36/lib/python3.6/site-packages/ipykernel_launcher.py:48: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", padding=\"same\", name=\"conv5b\", strides=(1, 1, 1))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 30, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 30, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 15, 30, 30, 64)    55360     \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 15, 30, 30, 64)    110656    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 7, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 7, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 7, 15, 15, 128)    442496    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 3, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 3, 7, 7, 256)      884992    \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 3, 7, 7, 256)      1769728   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 3, 9, 9, 256)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 256)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 5,862,597\n",
      "Trainable params: 5,862,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "Source path =  ./Project_data/val ; batch size = 20Source path = \n",
      " ./Project_data/train ; batch size = 20\n",
      "34/34 [==============================] - 33s 959ms/step - loss: 2.3190 - categorical_accuracy: 0.1961 - val_loss: 1.6067 - val_categorical_accuracy: 0.1800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2119_50_53.798608/model-00001-2.33670-0.19683-1.60673-0.18000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d1(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 30, 120, 120, 16)  6928      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 40, 40, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 10, 40, 40, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 10, 40, 40, 32)    27680     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10, 40, 40, 32)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 4, 14, 14, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 5, 5, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 929,461\n",
      "Trainable params: 928,437\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "Source path =  ./Project_data/trainSource path =  ; batch size = 20\n",
      " ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 46s 1s/step - loss: 1.4890 - categorical_accuracy: 0.3522 - val_loss: 10.0219 - val_categorical_accuracy: 0.3700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2119_51_27.424559/model-00001-1.48241-0.35546-10.02185-0.37000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d2(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 28, 118, 118, 8)   656       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 28, 59, 59, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 26, 57, 57, 16)    3472      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 26, 28, 28, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 24, 26, 26, 32)    13856     \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 22, 24, 24, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 22, 12, 12, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_5 (Conv3D)            (None, 21, 11, 11, 64)    16448     \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 20, 10, 10, 64)    32832     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 20, 5, 5, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               16384512  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 16,612,069\n",
      "Trainable params: 16,612,069\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "34/34 [==============================] - 45s 1s/step - loss: 1.7867 - categorical_accuracy: 0.2507 - val_loss: 12.4109 - val_categorical_accuracy: 0.2300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2018-10-2119_52_14.790328/model-00001-1.79843-0.24585-12.41093-0.23000.h5\n"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d3(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# batch size = 20\n",
      "# epochs = 1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 30, 120, 120, 8)   656       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 120, 120, 8)   32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 30, 120, 120, 8)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 15, 60, 60, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 15, 60, 60, 16)    3472      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 7, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 7, 30, 30, 32)     4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 3, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 3, 15, 15, 64)     18496     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 864,101\n",
      "Trainable params: 863,989\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "Source path =  ./Project_data/train ; batch size = 20\n",
      "Source path =  ./Project_data/val ; batch size = 20\n",
      "22/34 [==================>...........] - ETA: 16s - loss: 2.2920 - categorical_accuracy: 0.2008"
     ]
    }
   ],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d4(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(affine=True, flip=True, normalize=True, crop=True, edge=True)\n",
    "val_gen = DataGenerator()\n",
    "model_gen = ModelGenerator()\n",
    "\n",
    "input_shape = (30,120,120, 3)\n",
    "num_classes = 5\n",
    "\n",
    "model = model_gen.c3d5(input_shape, num_classes)\n",
    "\n",
    "batch_size = 20\n",
    "num_epochs = 1\n",
    "\n",
    "train_generator = train_gen.generator(train_path, train_doc, batch_size)\n",
    "val_generator = val_gen.generator(val_path, val_doc, batch_size)\n",
    "train(batch_size, num_epochs, model, train_generator, val_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
